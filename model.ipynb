{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "train_data = pd.read_csv(\"../population-segmentation-data/train_data.csv\", sep=\";\", index_col=0)\n",
    "test_data = pd.read_csv(\"../population-segmentation-data/test_data.csv\", sep=\";\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0         2         1.0       8.0                   8.0                 15.0   \n",
       "1         1         4.0      13.0                  13.0                  1.0   \n",
       "2         1         1.0       9.0                   7.0                  0.0   \n",
       "3         2         1.0       6.0                   6.0                  4.0   \n",
       "4         2         1.0       9.0                   9.0                 53.0   \n",
       "\n",
       "   ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  \\\n",
       "0           0.0         0.0           1.0                        13.0   \n",
       "1           0.0         0.0           2.0                         1.0   \n",
       "2          -1.0         0.0           0.0                         1.0   \n",
       "3           0.0         0.0           2.0                         4.0   \n",
       "4           0.0         0.0           1.0                        44.0   \n",
       "\n",
       "   ANZ_TITEL  ...  VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  \\\n",
       "0        0.0  ...       5.0         2.0      1.0             6.0   \n",
       "1        0.0  ...       1.0         2.0      1.0             4.0   \n",
       "2        0.0  ...       6.0         4.0      2.0            -1.0   \n",
       "3        0.0  ...       8.0        11.0     11.0             6.0   \n",
       "4        0.0  ...       2.0         2.0      1.0             6.0   \n",
       "\n",
       "   WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  RESPONSE  ANREDE_KZ  \\\n",
       "0             9.0       3.0         3         0          2   \n",
       "1             9.0       7.0         1         0          2   \n",
       "2             9.0       2.0         3         0          1   \n",
       "3             9.0       1.0         3         0          2   \n",
       "4             9.0       3.0         3         0          1   \n",
       "\n",
       "   ALTERSKATEGORIE_GROB  \n",
       "0                     4  \n",
       "1                     3  \n",
       "2                     4  \n",
       "3                     4  \n",
       "4                     3  \n",
       "\n",
       "[5 rows x 359 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([42419.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,   532.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphing the distribution of the RESPONSE variable for the training data\n",
    "plt.hist(train_data[\"RESPONSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01238620753882331"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the percentage of positive outcomes for the training data\n",
    "len(train_data[train_data[\"RESPONSE\"]==1]) / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into features and labels\n",
    "X_train = train_data.loc[:, train_data.columns != 'RESPONSE']\n",
    "y_train = train_data['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using logistic regrsssion to create the benchmark model\n",
    "\n",
    "# importing the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creating the logistic regression model with lasso regularization\n",
    "lr_baseline = LogisticRegression(penalty='l1',\n",
    "                                 class_weight='balanced',\n",
    "                                 solver='saga',\n",
    "                                 max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=5000, penalty='l1',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the baseline model\n",
    "lr_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing functions for calculating accuracy, precision, and recall\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for the training set\n",
    "y_pred = lr_baseline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9669390701031408\n",
      "The recall is 0.03007518796992481\n",
      "The precision is 0.017391304347826087\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, precision, and recall\n",
    "print(\"The accuracy is\", accuracy_score(y_train, y_pred))\n",
    "print(\"The recall is\", recall_score(y_train, y_pred))\n",
    "print(\"The precision is\", precision_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.82412374e-01 -2.05964717e-01 -2.15469814e-02 -9.61548525e-02\n",
      "  -1.49622347e-01  9.82935169e-02  1.88281323e-01  5.71469812e-02\n",
      "   1.33836078e-01  3.67708615e-02 -1.16476446e-04  1.13137463e-01\n",
      "  -1.58973469e-01 -1.87991094e-02 -1.56318610e-01 -1.28247893e-01\n",
      "   8.09685482e-02 -2.34751329e-02  4.01861648e-02  3.49127847e-02\n",
      "   7.35268549e-02 -4.60560280e-02  2.32292860e-02  5.25285924e-02\n",
      "   1.15832060e-01 -3.11725675e-01 -1.57269000e-02 -2.35702372e-01\n",
      "   9.21890392e-02 -9.28846180e-02  1.63144245e-01 -1.18039705e-01\n",
      "   1.56167154e-01 -8.63791933e-02 -1.58261687e-01  3.08860044e-03\n",
      "  -7.48185505e-02 -7.66403466e-02 -5.70312069e-02  1.50259870e-01\n",
      "   5.43324998e-02 -1.00404193e-01 -1.14898385e-01 -1.27747130e-01\n",
      "   3.09555835e-01 -1.17768963e-01  1.27161695e-01  7.96396984e-03\n",
      "   8.43813749e-02  4.15168794e-02 -1.23951625e-01 -4.80327698e-01\n",
      "  -9.81048044e-01  9.04135436e-02 -8.15590054e-02 -1.05832353e-01\n",
      "   1.10317556e-01 -1.60729295e-01  1.09788242e-01  5.44859563e-02\n",
      "  -8.06574275e-02  1.77617413e-01 -9.91690714e-01 -1.41490043e-01\n",
      "  -5.08783463e-02 -2.42314905e-02 -3.06342279e-02  1.84206541e-01\n",
      "   1.79147406e-01 -4.68376041e-02  1.01740740e-01 -5.30429011e-02\n",
      "  -2.66603231e-01 -4.91810226e-02 -5.50912090e-02 -5.12092926e-03\n",
      "  -1.17351236e-01 -6.33818590e-02  2.70239373e-02  2.10264494e-01\n",
      "  -2.58482340e-02 -2.19193190e-02  7.07574676e-02  4.85875859e-02\n",
      "  -6.09460358e-02  3.48162625e-02  8.58862316e-04 -6.93602004e-02\n",
      "   4.72358652e-02 -2.98022654e-03  1.14000090e-04  2.14612240e-01\n",
      "  -2.17814035e-02  3.48199678e-02 -1.51935005e-02  5.22786397e-02\n",
      "  -1.53550600e-01  9.86580048e-02  1.62131078e-01  2.61534097e-02\n",
      "   4.47204085e-02 -2.57075963e-02 -3.43553277e-02 -4.83897126e-03\n",
      "   3.98234516e-02  1.35270550e-01 -2.37643478e-02  2.87944592e-02\n",
      "   5.51277950e-02 -1.18589765e-01 -2.70984819e-01  1.45569474e-01\n",
      "   5.31852978e-02 -2.00562201e-01 -3.39942795e-02 -1.77390478e-01\n",
      "  -6.88657922e-02  5.93151068e-02 -3.94172081e-02 -1.42497632e-02\n",
      "  -2.19904690e-01 -1.73007858e-01  4.17776466e-02 -1.05252336e-01\n",
      "   1.47778670e-02  3.27188383e-01  4.03480439e-01 -5.66924212e-02\n",
      "   7.10445998e-02 -1.45836372e-01 -6.46618467e-02  5.06758353e-02\n",
      "   1.80159924e-01 -1.12399322e-01  2.18692222e-01  2.21281499e-02\n",
      "  -1.68552303e-01 -4.48805624e-02 -9.69702382e-02  1.27586276e-01\n",
      "  -1.17328872e-02 -9.43514246e-02  1.18243634e-01  3.01509952e-02\n",
      "  -1.11201467e-01  1.81689926e-01  4.60941205e-02 -1.60074184e-01\n",
      "   1.30730366e-01 -1.83835687e-01 -1.22571979e-02  8.69490727e-02\n",
      "   1.97756783e-01  3.03728666e-02 -6.26197319e-02 -1.48869545e-01\n",
      "   3.92746904e-02 -1.65391919e-01  1.87592931e-01 -1.37347002e-01\n",
      "  -1.64504941e-01  2.60880528e-01 -7.97005183e-03  5.02038637e-02\n",
      "  -4.60041892e-02  1.66153103e-01 -3.25954407e-02 -8.43020459e-02\n",
      "  -3.56529555e-02  2.38398629e-01  3.10656973e-02 -4.49894134e-02\n",
      "   1.38271584e-01 -1.21423630e-01 -4.06628964e-02  2.54183587e-01\n",
      "   4.43477136e-02 -6.90947222e-02 -1.71901431e-02  2.70536082e-02\n",
      "   8.12829415e-02 -3.84265023e-02 -4.01705748e-02  5.81500042e-02\n",
      "  -3.15131748e-03  3.04326887e-02 -5.44505674e-02 -2.90719060e-02\n",
      "  -8.55402046e-02 -9.01155787e-02  2.06597152e-02  1.19165270e-01\n",
      "  -1.00748287e-01  6.82343924e-02 -1.01503644e-01 -1.21892188e-01\n",
      "   1.49394785e-01 -2.00956418e-01  3.29709574e-02  1.64567119e-02\n",
      "   1.50250797e-02 -1.18802009e-01  1.62645892e-01  3.43953092e-03\n",
      "  -1.90297552e-01  1.47004543e-01  2.17698694e-01 -1.43460685e-01\n",
      "   6.43172405e-02 -1.07766264e-01  8.17308663e-02 -3.03615638e-03\n",
      "   6.75438939e-04  8.94163249e-02 -1.24006348e-01  7.15822830e-02\n",
      "  -6.70511165e-02 -5.49988511e-02  4.90529502e-03 -2.66649696e-02\n",
      "  -3.85537678e-02  1.03197456e-01  1.05007090e-01  5.33922900e-02\n",
      "   7.20218265e-02  3.48253951e-02  5.86505199e-02  7.97797386e-02\n",
      "  -6.24121746e-02 -1.07766264e-01 -6.16094838e-02  1.20366070e-01\n",
      "   1.61710870e-01  9.90929690e-03 -5.99263474e-02  1.31464553e-02\n",
      "  -4.66125756e-02 -2.06215109e-02  1.32320783e-02 -8.44813166e-02\n",
      "   2.33819519e-02 -1.19725588e-01  1.23316172e-01 -1.70398197e-01\n",
      "  -2.99965370e-03  9.34067719e-03 -1.32611548e-01  3.77660594e-02\n",
      "  -1.91237242e-02 -1.42184208e-01 -1.57536388e-01  5.57809950e-02\n",
      "   2.42364061e-01 -9.84858761e-02  1.36062633e-01 -1.20091807e-01\n",
      "  -4.56695973e-02  8.97416308e-02 -6.17436330e-02  9.35300658e-02\n",
      "  -1.29064839e-01  1.34862515e-02  8.45635619e-02  9.68096995e-02\n",
      "  -7.24024826e-02 -4.57144100e-02  7.47326313e-02  1.40329713e-01\n",
      "   4.96849386e-03  1.37029791e-04 -1.23944171e-02 -3.59801761e-02\n",
      "  -1.81194262e-01 -1.13823753e-01 -1.15515827e-01 -1.97646123e-01\n",
      "  -3.23118687e-02  1.05729765e-01 -9.36952766e-02  2.21307302e-03\n",
      "  -1.07356573e-01  2.60565489e-01 -8.74406405e-02 -1.19867734e-01\n",
      "   1.32130630e-01 -2.61743435e-02 -1.79275567e-02  1.79129242e-01\n",
      "  -2.06492098e-02 -1.64842137e-01 -7.87101794e-02  7.70822248e-02\n",
      "  -7.78530064e-02  1.28081757e-01  6.99861870e-02 -1.89635708e-01\n",
      "   1.21033386e-01  1.17033648e-02  2.64364091e-02 -6.01201086e-02\n",
      "   1.34251036e-01 -1.70614535e-02 -5.80129796e-02 -5.72680271e-03\n",
      "   6.14886475e-02 -1.64979364e-01 -1.50782522e-02 -1.16193299e-01\n",
      "  -9.24550482e-02  4.83896511e-02  2.35773710e-03 -7.83899447e-02\n",
      "   1.81331847e-02  1.22579442e-01  6.01569485e-02 -9.63715100e-02\n",
      "  -5.56515743e-02 -7.08870455e-02  5.63310807e-02  2.39118765e-01\n",
      "  -6.44864486e-02 -4.00977458e-02  3.03420252e-01  1.72808644e-01\n",
      "   6.43093281e-02 -1.60323086e-01  4.02020827e-02  6.99111708e-02\n",
      "   1.37872718e-01  1.59035037e-01  2.25373523e-01  7.93577474e-02\n",
      "  -1.56826542e-02 -2.18365035e-03  4.04286741e-02  1.59824774e-01\n",
      "  -1.25830816e-01 -1.78309244e-01 -1.01190983e-01  1.75959287e-02\n",
      "   1.24922522e-01 -6.95698824e-05  9.34476238e-02  4.02054895e-02\n",
      "   3.96751372e-02  2.33176096e-02  1.19566478e-01 -9.57399314e-02\n",
      "  -7.00608354e-03 -3.62077834e-02 -1.18514680e-01 -1.13032168e-02\n",
      "   1.60894084e-01  1.89041608e-01  2.09072927e-01 -2.22506157e-01\n",
      "  -7.55774369e-02 -9.39577649e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the coefficents learned by the model\n",
    "coefs = lr_baseline.coef_\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "print(len(coefs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SMOTE class in order to oversample the positive class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Creating the SMOTE model\n",
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the SMOTE model to the training data and resampling the training data\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f92a78ab3d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the new distribution of the RESPONSE column\n",
    "y_train_over.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retraining the baseline with the balanced data\n",
    "\n",
    "# Creating the logistic regression model with lasso regularization\n",
    "lr_baseline = LogisticRegression(penalty='l1',\n",
    "                                 class_weight='balanced',\n",
    "                                 solver='saga',\n",
    "                                 max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=10000, penalty='l1',\n",
       "                   solver='saga')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the baseline model with the balanced data\n",
    "lr_baseline.fit(X_train_over, y_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for the training set\n",
    "y_pred = lr_baseline.predict(X_train_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.8624555034300667\n",
      "The recall is 0.8970508498550178\n",
      "The precision is 0.8389998677073687\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, precision, and recall\n",
    "print(\"The accuracy is\", accuracy_score(y_train_over, y_pred))\n",
    "print(\"The recall is\", recall_score(y_train_over, y_pred))\n",
    "print(\"The precision is\", precision_score(y_train_over, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cross validation to select a model\n",
    "\n",
    "# Importing the cross validation function\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Importing the classes that will be used to create the models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Creating the models\n",
    "\n",
    "# Random forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200)\n",
    "# Gradient boosting model\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=200)\n",
    "# XGBoost model\n",
    "xgb_classifier = XGBClassifier()\n",
    "# K nearest neighbors model\n",
    "knn_classifier= KNeighborsClassifier()\n",
    "# Naive bayes model\n",
    "nb_classifier = GaussianNB()\n",
    "# Support vector machine model\n",
    "svm_classifier = SVC(max_iter=500)\n",
    "# Logistic regression classifier\n",
    "lr_classifier = LogisticRegression(penalty='l1',\n",
    "                                   solver='saga',\n",
    "                                   max_iter=10000)\n",
    "\n",
    "# Dictionary that will hold the accuracy, recall, and precision values for the cross validation process for each model\n",
    "cv_scores = {\"Random Forest\": None, \"Gradient Boosting\": None, \"XGBoost\": None,\n",
    "             \"K Nearest Neighbors\": None, \"Naive Bayes\": None, \"Logistic Regression\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the feature and the labels to get a random sample\n",
    "X_train_over[\"RESPONSE\"] = y_train_over\n",
    "# Renaming the dataframe\n",
    "sampled_combined = X_train_over.copy()\n",
    "# Getting a random sample from the data to reduce the runtime of the cross validation iterations\n",
    "df_sample = sampled_combined.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "      <th>RESPONSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84714</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.705560</td>\n",
       "      <td>9.073610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.963195</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.981598</td>\n",
       "      <td>2.963195</td>\n",
       "      <td>1.981598</td>\n",
       "      <td>2.055207</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.963195</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49511</th>\n",
       "      <td>1</td>\n",
       "      <td>5.949205</td>\n",
       "      <td>11.525397</td>\n",
       "      <td>11.144048</td>\n",
       "      <td>0.381349</td>\n",
       "      <td>-0.618651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762699</td>\n",
       "      <td>0.381349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.381349</td>\n",
       "      <td>8.618651</td>\n",
       "      <td>6.237301</td>\n",
       "      <td>1.669446</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36567</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30738</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76344</th>\n",
       "      <td>-1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.819184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.542448</td>\n",
       "      <td>1.819184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.553471</td>\n",
       "      <td>11.191839</td>\n",
       "      <td>9.553471</td>\n",
       "      <td>5.276736</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.638368</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGER_TYP  AKT_DAT_KL   ALTER_HH  ALTERSKATEGORIE_FEIN  \\\n",
       "84714         1    1.000000  15.705560              9.073610   \n",
       "49511         1    5.949205  11.525397             11.144048   \n",
       "36567         1    1.000000  10.000000             10.000000   \n",
       "30738        -1    1.000000  21.000000             15.000000   \n",
       "76344        -1    1.000000   0.000000              0.000000   \n",
       "\n",
       "       ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  \\\n",
       "84714             1.000000      0.000000         0.0      3.963195   \n",
       "49511             0.381349     -0.618651         0.0      0.762699   \n",
       "36567             1.000000      0.000000         0.0      2.000000   \n",
       "30738             1.000000      0.000000         0.0      4.000000   \n",
       "76344             1.819184      0.000000         0.0      1.542448   \n",
       "\n",
       "       ANZ_STATISTISCHE_HAUSHALTE  ANZ_TITEL  ...  VK_DHT4A  VK_DISTANZ  \\\n",
       "84714                    1.000000        0.0  ...  1.981598    2.963195   \n",
       "49511                    0.381349        0.0  ...  6.381349    8.618651   \n",
       "36567                    1.000000        0.0  ...  1.000000    1.000000   \n",
       "30738                    1.000000        0.0  ...  3.000000    5.000000   \n",
       "76344                    1.819184        0.0  ...  8.553471   11.191839   \n",
       "\n",
       "        VK_ZG11  W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  \\\n",
       "84714  1.981598        2.055207             9.0  2.963195         1   \n",
       "49511  6.237301        1.669446             9.0  7.000000         2   \n",
       "36567  1.000000        6.000000             9.0  7.000000         3   \n",
       "30738  3.000000        4.000000             9.0  2.000000         1   \n",
       "76344  9.553471        5.276736             9.0  4.638368         2   \n",
       "\n",
       "       ANREDE_KZ  ALTERSKATEGORIE_GROB  RESPONSE  \n",
       "84714          1                     4         1  \n",
       "49511          1                     4         1  \n",
       "36567          2                     3         0  \n",
       "30738          1                     3         0  \n",
       "76344          1                     3         1  \n",
       "\n",
       "[5 rows x 359 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the data into features and labels\n",
    "X_sample = df_sample.loc[:, df_sample.columns != \"RESPONSE\"]\n",
    "y_sample = df_sample[\"RESPONSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest \n",
      "\n",
      "The mean training accuracy is 0.949775\n",
      "The mean training recall is 0.9279618473895581\n",
      "The mean training precision is 0.969964198008823\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.9422\n",
      "The mean test recall is 0.9128514056224899\n",
      "The mean test precision is 0.9694681101562276\n",
      "\n",
      "\n",
      "GBM \n",
      "\n",
      "The mean training accuracy is 0.9460750000000001\n",
      "The mean training recall is 0.9170682730923694\n",
      "The mean training precision is 0.9731015139101732\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.9439\n",
      "The mean test recall is 0.9128514056224899\n",
      "The mean test precision is 0.9728557423346883\n",
      "\n",
      "\n",
      "XGBoost \n",
      "\n",
      "The mean training accuracy is 0.949775\n",
      "The mean training recall is 0.9279618473895581\n",
      "The mean training precision is 0.969964198008823\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.9429000000000001\n",
      "The mean test recall is 0.9142570281124497\n",
      "The mean test precision is 0.969490048426581\n",
      "\n",
      "\n",
      "KNN \n",
      "\n",
      "The mean training accuracy is 0.77055\n",
      "The mean training recall is 0.9625502008032129\n",
      "The mean training precision is 0.694895105568955\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.7198\n",
      "The mean test recall is 0.9614457831325302\n",
      "The mean test precision is 0.6473524638021894\n",
      "\n",
      "\n",
      "Naive Bayes \n",
      "\n",
      "The mean training accuracy is 0.64495\n",
      "The mean training recall is 0.7383032128514057\n",
      "The mean training precision is 0.6206565546730447\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.6437999999999999\n",
      "The mean test recall is 0.7375502008032128\n",
      "The mean test precision is 0.6197377408503414\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine \n",
      "\n",
      "The mean training accuracy is 0.5039999999999999\n",
      "The mean training recall is 0.4971385542168674\n",
      "The mean training precision is 0.49699478021027427\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.5031\n",
      "The mean test recall is 0.5014056224899599\n",
      "The mean test precision is 0.4992858592332758\n",
      "\n",
      "\n",
      "Logistic Regression \n",
      "\n",
      "The mean training accuracy is 0.8291000000000001\n",
      "The mean training recall is 0.8257028112449799\n",
      "The mean training precision is 0.8303287656856421\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.8169000000000001\n",
      "The mean test recall is 0.8138554216867468\n",
      "The mean test precision is 0.8176011897028355\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating each machine learning model using cross validation\n",
    "\n",
    "# Importing the cross validation function\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Creating a dictionary where each the key is the model name and the value is the model\n",
    "models = {\"Random forest\":rf_classifier, \"GBM\":gb_classifier, \"XGBoost\":xgb_classifier,\n",
    "          \"KNN\":knn_classifier, \"Naive Bayes\":nb_classifier, \"Support Vector Machine\":svm_classifier,\n",
    "          \"Logistic Regression\":lr_classifier}\n",
    "\n",
    "# Looping through all the models\n",
    "for model_name in models:\n",
    "    # Performing 5 fold cross validation\n",
    "    results = cross_validate(models[model_name], X_sample, y_sample, cv=5,\n",
    "                             scoring=[\"recall\", \"precision\", \"accuracy\"],\n",
    "                             return_train_score=True)\n",
    "    # Displaying the results\n",
    "    print(model_name, '\\n')\n",
    "    \n",
    "    # Displaying the training accuracy metrics\n",
    "    print(\"The mean training accuracy is\", results[\"train_accuracy\"].mean())\n",
    "    print(\"The mean training recall is\", results[\"train_recall\"].mean())\n",
    "    print(\"The mean training precision is\", results[\"train_precision\"].mean())\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    # Displaying the test accuracy metrics\n",
    "    print(\"The mean test accuracy is\", results[\"test_accuracy\"].mean())\n",
    "    print(\"The mean test recall is\", results[\"test_recall\"].mean())\n",
    "    print(\"The mean test precision is\", results[\"test_precision\"].mean())\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing feature selection and hyperparameter tuning for the best models\n",
    "\n",
    "# Importing the libraries\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Creating pipelines for the different models\n",
    "rf_pipline = Pipeline([\n",
    "    ('selector', SelectKBest(f_classif)),\n",
    "    ('model', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "xgb_pipline = Pipeline([\n",
    "    ('selector', SelectKBest(f_classif)),\n",
    "    ('model', XGBClassifier())\n",
    "])\n",
    "\n",
    "knn_pipline = Pipeline([\n",
    "    ('selector', SelectKBest(f_classif)),\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Creating the parameter grids for each model\n",
    "rf_param_grid = {\n",
    "    'selector__k': [100, 230, 270, 300, 350],\n",
    "    'model__max_depth': [3, 10, 20, 50, 100, 150, 200],\n",
    "    'model__n_estimators': [100, 200, 300]\n",
    "}\n",
    "\n",
    "# Creating the grid search models for each model\n",
    "rf_search = GridSearchCV(\n",
    "    estimator = rf_pipline,\n",
    "    param_grid = rf_param_grid,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'recall', 'precision'],\n",
    "    verbose=3,\n",
    "    refit=\"accuracy\"\n",
    ")\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'selector__k': [100, 230, 270, 300, 350],\n",
    "    'model__max_depth': [3, 10, 20, 50, 100, 150, 200],\n",
    "    'model__learning_rate': [0.001, 0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "xgb_search = GridSearchCV(\n",
    "    estimator = xgb_pipline,\n",
    "    param_grid = xgb_param_grid,\n",
    "    n_jobs=-1,\n",
    "    scoring=['accuracy', 'recall', 'precision'],\n",
    "    verbose=3,\n",
    "    refit=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a random sample of 5000 points from the data in order to speed up the run time\n",
    "\n",
    "# Combining the feature and the labels to get a random sample\n",
    "X_train_over[\"RESPONSE\"] = y_train_over\n",
    "# Renaming the dataframe\n",
    "sampled_combined = X_train_over.copy()\n",
    "# Getting a random sample from the data to reduce the runtime of the cross validation iterations\n",
    "df_sample = sampled_combined.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the data into features and labels\n",
    "X_sample = df_sample.loc[:, df_sample.columns != \"RESPONSE\"]\n",
    "y_sample = df_sample[\"RESPONSE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 105 candidates, totalling 525 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   28.2s\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 525 out of 525 | elapsed:  5.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', SelectKBest()),\n",
       "                                       ('model', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [3, 10, 20, 50, 100, 150, 200],\n",
       "                         'model__n_estimators': [100, 200, 300],\n",
       "                         'selector__k': [100, 230, 270, 300, 350]},\n",
       "             refit='accuracy', scoring=['accuracy', 'recall', 'precision'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_search.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 20, 'model__n_estimators': 300, 'selector__k': 350}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the best model parameters\n",
    "rf_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322000000000001"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cross validation to evaluate the best random forest model\n",
    "rf_tuned_results = cross_validate(rf_search.best_estimator_, X_sample, y_sample, cv=5,\n",
    "                                  scoring=[\"recall\", \"precision\", \"accuracy\"],\n",
    "                                  return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean training accuracy is 0.94345\n",
      "The mean training recall is 0.9175728244088729\n",
      "The mean training precision is 0.9669338707834945\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.9312000000000001\n",
      "The mean test recall is 0.8984325306678782\n",
      "The mean test precision is 0.9607043774434718\n"
     ]
    }
   ],
   "source": [
    "# Displaying the evaluation metrics\n",
    "display_metrics(rf_tuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 140 candidates, totalling 700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 13.9min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=-1)]: Done 700 out of 700 | elapsed: 34.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', SelectKBest()),\n",
       "                                       ('model',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      mo...\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__learning_rate': [0.001, 0.01, 0.05, 0.1],\n",
       "                         'model__max_depth': [3, 10, 20, 50, 100, 150, 200],\n",
       "                         'selector__k': [100, 230, 270, 300, 350]},\n",
       "             refit='accuracy', scoring=['accuracy', 'recall', 'precision'],\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_search.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__learning_rate': 0.1, 'model__max_depth': 10, 'selector__k': 230}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the best model parameters\n",
    "xgb_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using cross validation to evaluate the best random forest model\n",
    "xgb_tuned_results = cross_validate(xgb_search.best_estimator_, X_sample, y_sample, cv=5,\n",
    "                                   scoring=[\"recall\", \"precision\", \"accuracy\"],\n",
    "                                   return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean training accuracy is 0.9492750000000001\n",
      "The mean training recall is 0.9190910328175397\n",
      "The mean training precision is 0.9778013438996311\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.9423\n",
      "The mean test recall is 0.9058978139236988\n",
      "The mean test precision is 0.9766745782030386\n"
     ]
    }
   ],
   "source": [
    "display_metrics(xgb_tuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best = SelectKBest(f_classif, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=100)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_best.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , 12.        , 12.        , ...,  3.        ,\n",
       "         2.        ,  3.        ],\n",
       "       [ 1.        , 10.        ,  5.68180793, ...,  3.        ,\n",
       "         2.        ,  3.        ],\n",
       "       [ 1.        ,  9.37433509,  3.16755322, ...,  2.        ,\n",
       "         1.        ,  4.        ],\n",
       "       ...,\n",
       "       [ 1.        ,  7.        , 10.        , ...,  3.        ,\n",
       "         1.        ,  4.        ],\n",
       "       [ 1.        , 10.        ,  1.        , ...,  3.        ,\n",
       "         2.        ,  4.        ],\n",
       "       [ 1.        ,  6.        ,  1.        , ...,  3.        ,\n",
       "         2.        ,  3.        ]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_best.transform(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using random search to tune the hyperparamaters of the tree based models\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(3, 300, num = 20)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4, 10, 30, 80, 100]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 29.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [3, 18, 34, 49, 65, 81, 96,\n",
       "                                                      112, 128, 143, 159, 174,\n",
       "                                                      190, 206, 221, 237, 253,\n",
       "                                                      268, 284, 300, None],\n",
       "                                        'max_features': ['auto', 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 10, 30,\n",
       "                                                             80, 100],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using random search to find for best hyperparameters\n",
    "\n",
    "# Baseline model that will be tuned, all hyperparameters are set to default\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters using 3 fold cross validation, \n",
    "# search across 100 different combinations and use all available cores to speed up search\n",
    "rf_random_search = RandomizedSearchCV(estimator = rf_classifier, param_distributions = random_grid,\n",
    "                                      n_iter = 100, cv = 3, verbose=2, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random_search.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 190,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the best set of parameters\n",
    "rf_random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the random forest model with the tuned hyperparameters using cross validation\n",
    "\n",
    "tuned_results = cross_validate(rf_random_search.best_estimator_, X_sample, y_sample, cv=5,\n",
    "                               scoring=[\"recall\", \"precision\", \"accuracy\"],\n",
    "                               return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_metrics(results):\n",
    "    \"\"\"\n",
    "    Displays the accuracy, precision, and recall of a model that it trained using cross validation\n",
    "    param results: A dictionary that holds the accuracy, recall, and precision of a model\n",
    "    return: Displays the accuracy, recall, and precision of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Displaying the training accuracy metrics\n",
    "    print(\"The mean training accuracy is\", results[\"train_accuracy\"].mean())\n",
    "    print(\"The mean training recall is\", results[\"train_recall\"].mean())\n",
    "    print(\"The mean training precision is\", results[\"train_precision\"].mean())\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    # Displaying the test accuracy metrics\n",
    "    print(\"The mean test accuracy is\", results[\"test_accuracy\"].mean())\n",
    "    print(\"The mean test recall is\", results[\"test_recall\"].mean())\n",
    "    print(\"The mean test precision is\", results[\"test_precision\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean training accuracy is 0.949325\n",
      "The mean training recall is 0.9269743622945551\n",
      "The mean training precision is 0.9719815306072966\n",
      "\n",
      "\n",
      "The mean test accuracy is 0.9404\n",
      "The mean test recall is 0.9113661223381561\n",
      "The mean test precision is 0.9694884885105516\n"
     ]
    }
   ],
   "source": [
    "# Displaying the evaluation metrics\n",
    "display_metrics(tuned_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
