{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "general_data = pd.read_csv(\"../population-segmentation-data/general_data.csv\", sep=\";\")\n",
    "customer_data = pd.read_csv(\"../population-segmentation-data/customer_data.csv\", sep=\";\")\n",
    "train_data = pd.read_csv(\"../population-segmentation-data/train_data.csv\", sep=\";\")\n",
    "test_data = pd.read_csv(\"../population-segmentation-data/test_data.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTERSKATEGORIE_FEIN  \\\n",
       "0           0         2         1.0       8.0                   8.0   \n",
       "1           1         1         4.0      13.0                  13.0   \n",
       "2           2         1         1.0       9.0                   7.0   \n",
       "3           3         2         1.0       6.0                   6.0   \n",
       "4           4         2         1.0       9.0                   9.0   \n",
       "\n",
       "   ANZ_HAUSHALTE_AKTIV  ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  \\\n",
       "0                 15.0           0.0         0.0           1.0   \n",
       "1                  1.0           0.0         0.0           2.0   \n",
       "2                  0.0          -1.0         0.0           0.0   \n",
       "3                  4.0           0.0         0.0           2.0   \n",
       "4                 53.0           0.0         0.0           1.0   \n",
       "\n",
       "   ANZ_STATISTISCHE_HAUSHALTE  ...  VK_DHT4A  VK_DISTANZ  VK_ZG11  \\\n",
       "0                        13.0  ...       5.0         2.0      1.0   \n",
       "1                         1.0  ...       1.0         2.0      1.0   \n",
       "2                         1.0  ...       6.0         4.0      2.0   \n",
       "3                         4.0  ...       8.0        11.0     11.0   \n",
       "4                        44.0  ...       2.0         2.0      1.0   \n",
       "\n",
       "   W_KEIT_KIND_HH  WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  RESPONSE  ANREDE_KZ  \\\n",
       "0             6.0             9.0       3.0         3         0          2   \n",
       "1             4.0             9.0       7.0         1         0          2   \n",
       "2            -1.0             9.0       2.0         3         0          1   \n",
       "3             6.0             9.0       1.0         3         0          2   \n",
       "4             6.0             9.0       3.0         3         0          1   \n",
       "\n",
       "   ALTERSKATEGORIE_GROB  \n",
       "0                     4  \n",
       "1                     3  \n",
       "2                     4  \n",
       "3                     4  \n",
       "4                     3  \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n"
     ]
    }
   ],
   "source": [
    "# Getting the name of the extra column\n",
    "extra_col = list(general_data.columns)[0]\n",
    "print(extra_col)\n",
    "\n",
    "# Removing the extra column in every dataframe since it is redundant\n",
    "general_data.drop(extra_col, axis=1, inplace=True)\n",
    "customer_data.drop(extra_col, axis=1, inplace=True)\n",
    "train_data.drop(extra_col, axis=1, inplace=True)\n",
    "test_data.drop(extra_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGER_TYP</th>\n",
       "      <th>AKT_DAT_KL</th>\n",
       "      <th>ALTER_HH</th>\n",
       "      <th>ALTERSKATEGORIE_FEIN</th>\n",
       "      <th>ANZ_HAUSHALTE_AKTIV</th>\n",
       "      <th>ANZ_HH_TITEL</th>\n",
       "      <th>ANZ_KINDER</th>\n",
       "      <th>ANZ_PERSONEN</th>\n",
       "      <th>ANZ_STATISTISCHE_HAUSHALTE</th>\n",
       "      <th>ANZ_TITEL</th>\n",
       "      <th>...</th>\n",
       "      <th>VK_DHT4A</th>\n",
       "      <th>VK_DISTANZ</th>\n",
       "      <th>VK_ZG11</th>\n",
       "      <th>W_KEIT_KIND_HH</th>\n",
       "      <th>WOHNDAUER_2008</th>\n",
       "      <th>WOHNLAGE</th>\n",
       "      <th>ZABEOTYP</th>\n",
       "      <th>RESPONSE</th>\n",
       "      <th>ANREDE_KZ</th>\n",
       "      <th>ALTERSKATEGORIE_GROB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 359 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGER_TYP  AKT_DAT_KL  ALTER_HH  ALTERSKATEGORIE_FEIN  ANZ_HAUSHALTE_AKTIV  \\\n",
       "0         2         1.0       8.0                   8.0                 15.0   \n",
       "1         1         4.0      13.0                  13.0                  1.0   \n",
       "2         1         1.0       9.0                   7.0                  0.0   \n",
       "3         2         1.0       6.0                   6.0                  4.0   \n",
       "4         2         1.0       9.0                   9.0                 53.0   \n",
       "\n",
       "   ANZ_HH_TITEL  ANZ_KINDER  ANZ_PERSONEN  ANZ_STATISTISCHE_HAUSHALTE  \\\n",
       "0           0.0         0.0           1.0                        13.0   \n",
       "1           0.0         0.0           2.0                         1.0   \n",
       "2          -1.0         0.0           0.0                         1.0   \n",
       "3           0.0         0.0           2.0                         4.0   \n",
       "4           0.0         0.0           1.0                        44.0   \n",
       "\n",
       "   ANZ_TITEL  ...  VK_DHT4A  VK_DISTANZ  VK_ZG11  W_KEIT_KIND_HH  \\\n",
       "0        0.0  ...       5.0         2.0      1.0             6.0   \n",
       "1        0.0  ...       1.0         2.0      1.0             4.0   \n",
       "2        0.0  ...       6.0         4.0      2.0            -1.0   \n",
       "3        0.0  ...       8.0        11.0     11.0             6.0   \n",
       "4        0.0  ...       2.0         2.0      1.0             6.0   \n",
       "\n",
       "   WOHNDAUER_2008  WOHNLAGE  ZABEOTYP  RESPONSE  ANREDE_KZ  \\\n",
       "0             9.0       3.0         3         0          2   \n",
       "1             9.0       7.0         1         0          2   \n",
       "2             9.0       2.0         3         0          1   \n",
       "3             9.0       1.0         3         0          2   \n",
       "4             9.0       3.0         3         0          1   \n",
       "\n",
       "   ALTERSKATEGORIE_GROB  \n",
       "0                     4  \n",
       "1                     3  \n",
       "2                     4  \n",
       "3                     4  \n",
       "4                     3  \n",
       "\n",
       "[5 rows x 359 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([42419.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0.,   532.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graphing the distribution of the RESPONSE variable for the training data\n",
    "plt.hist(train_data[\"RESPONSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01238620753882331"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the percentage of positive outcomes for the training data\n",
    "len(train_data[train_data[\"RESPONSE\"]==1]) / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using logistic regrsssion to create the benchmark model\n",
    "\n",
    "# importing the logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creating the logistic regression model with lasso regularization\n",
    "lr_baseline = LogisticRegression(penalty='l1',\n",
    "                                 class_weight='balanced',\n",
    "                                 solver='saga',\n",
    "                                 max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the training data into features and labels\n",
    "X_train = train_data.loc[:, train_data.columns != 'RESPONSE']\n",
    "y_train = train_data['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=5000, multi_class='auto', n_jobs=None, penalty='l1',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the baseline model\n",
    "lr_baseline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing functions for calculating accuracy, precision, and recall\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting predictions for the training set\n",
    "y_pred = lr_baseline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9442853484202929\n",
      "The recall is 0.07142857142857142\n",
      "The precision is 0.01961796592669076\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, precision, and recall\n",
    "print(\"The accuracy is\", accuracy_score(y_train, y_pred))\n",
    "print(\"The recall is\", recall_score(y_train, y_pred))\n",
    "print(\"The precision is\", precision_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.84450348e-01 -2.06924868e-01 -1.83604229e-02 -9.67034363e-02\n",
      "  -1.50974351e-01  9.89577340e-02  1.88435767e-01  5.75442949e-02\n",
      "   1.31504100e-01  3.79114484e-02 -3.36496313e-03  1.09054392e-01\n",
      "  -1.56563181e-01 -1.81927307e-02 -1.57574565e-01 -1.27913420e-01\n",
      "   8.35027358e-02 -2.24811384e-02  3.93137707e-02  3.50727163e-02\n",
      "   7.34860695e-02 -5.05263893e-02  2.34382399e-02  5.24743427e-02\n",
      "   1.13680740e-01 -3.14355447e-01 -1.95534049e-02 -2.36826364e-01\n",
      "   8.91601647e-02 -9.67143652e-02  1.61971528e-01 -1.19515914e-01\n",
      "   1.61725556e-01 -8.70868310e-02 -1.54763680e-01  3.58326470e-03\n",
      "  -7.61265840e-02 -7.82205095e-02 -5.99056671e-02  1.50698931e-01\n",
      "   5.97688814e-02 -9.23379909e-02 -1.18042642e-01 -1.29907791e-01\n",
      "   3.05467440e-01 -1.20192910e-01  1.27846796e-01  8.01296853e-03\n",
      "   8.83863175e-02  4.45155169e-02 -1.21501853e-01 -4.80737431e-01\n",
      "  -9.79039480e-01  8.73312352e-02 -8.09821994e-02 -1.08705632e-01\n",
      "   1.09645954e-01 -1.65601828e-01  1.09122530e-01  5.31462755e-02\n",
      "  -7.88138286e-02  1.79365227e-01 -9.89806547e-01 -1.39000380e-01\n",
      "  -5.08219625e-02 -2.61221308e-02 -3.09865134e-02  1.81756291e-01\n",
      "   1.81040324e-01 -4.81381336e-02  1.02737521e-01 -5.36778152e-02\n",
      "  -2.67219876e-01 -5.47386109e-02 -5.73825482e-02 -4.23149065e-03\n",
      "  -1.15835786e-01 -5.86804423e-02  2.56368007e-02  2.13533435e-01\n",
      "  -2.84769550e-02 -2.41003642e-02  7.46078275e-02  5.02074088e-02\n",
      "  -5.93406509e-02  3.43178326e-02  1.20694346e-04 -6.92633164e-02\n",
      "   5.11537679e-02 -3.31912170e-03  3.38218440e-05  2.14851435e-01\n",
      "  -1.64128315e-02  3.78891690e-02 -1.87696718e-02  5.10650007e-02\n",
      "  -1.53056817e-01  9.61168806e-02  1.63824831e-01  2.19331064e-02\n",
      "   4.55649145e-02 -2.44605982e-02 -3.16966130e-02 -9.05395321e-03\n",
      "   3.61167767e-02  1.39304500e-01 -2.32664548e-02  2.71910742e-02\n",
      "   5.43731678e-02 -1.18317887e-01 -2.63497813e-01  1.45817392e-01\n",
      "   4.94316422e-02 -1.99065705e-01 -3.57819790e-02 -1.79616003e-01\n",
      "  -7.48506898e-02  6.17892078e-02 -3.41291021e-02 -1.71870355e-02\n",
      "  -2.23868312e-01 -1.72441005e-01  4.15126417e-02 -1.02328085e-01\n",
      "   1.03908076e-02  3.29192979e-01  3.97365191e-01 -5.91710634e-02\n",
      "   7.03539151e-02 -1.42922022e-01 -6.74690105e-02  4.52691097e-02\n",
      "   1.82375405e-01 -1.11065532e-01  2.15429061e-01  2.02720062e-02\n",
      "  -1.66477610e-01 -5.07871758e-02 -1.01454431e-01  1.27320659e-01\n",
      "  -1.16066709e-02 -9.48374764e-02  1.16174967e-01  2.54502309e-02\n",
      "  -1.13824519e-01  1.87194482e-01  4.76108422e-02 -1.56424212e-01\n",
      "   1.24176378e-01 -1.85444960e-01 -1.25777021e-02  8.32672901e-02\n",
      "   1.97480969e-01  2.94499484e-02 -6.27859091e-02 -1.48496283e-01\n",
      "   4.32954537e-02 -1.69081705e-01  1.93195947e-01 -1.33977983e-01\n",
      "  -1.63835430e-01  2.61833268e-01 -1.00330746e-02  4.67160998e-02\n",
      "  -4.28127054e-02  1.66013164e-01 -3.26455914e-02 -8.66790054e-02\n",
      "  -3.43177732e-02  2.40859952e-01  2.70204811e-02 -4.80145298e-02\n",
      "   1.33659058e-01 -1.22229995e-01 -3.74755523e-02  2.58354888e-01\n",
      "   4.72811886e-02 -6.98059589e-02 -1.79588755e-02  2.79715378e-02\n",
      "   7.98756873e-02 -3.99603267e-02 -4.00913556e-02  5.68954815e-02\n",
      "  -2.74556703e-03  2.48184212e-02 -5.55178926e-02 -2.69581031e-02\n",
      "  -8.32021264e-02 -8.79275885e-02  2.12091926e-02  1.16137004e-01\n",
      "  -1.05626524e-01  7.25236226e-02 -1.00945264e-01 -1.20227489e-01\n",
      "   1.50562353e-01 -2.06968249e-01  3.31812819e-02  2.06259987e-02\n",
      "   1.35697089e-02 -1.20457583e-01  1.59848124e-01  5.64278618e-03\n",
      "  -1.91882365e-01  1.48835854e-01  2.15363762e-01 -1.47475648e-01\n",
      "   6.91987242e-02 -1.10127468e-01  8.66964039e-02 -6.66677131e-03\n",
      "  -1.53451138e-03  8.93256199e-02 -1.22017605e-01  7.34689833e-02\n",
      "  -5.97349123e-02 -6.10924236e-02  5.22257092e-03 -2.98644921e-02\n",
      "  -4.18432299e-02  1.05607050e-01  1.06025732e-01  5.52884817e-02\n",
      "   7.06960794e-02  3.21091372e-02  5.73996404e-02  8.15815791e-02\n",
      "  -6.53099642e-02 -1.10127468e-01 -6.32857660e-02  1.23775504e-01\n",
      "   1.64205786e-01  1.06416850e-02 -5.90408389e-02  1.50127690e-02\n",
      "  -4.92419675e-02 -1.68223021e-02  1.56448039e-02 -8.29129231e-02\n",
      "   2.33564292e-02 -1.23261055e-01  1.25048956e-01 -1.70119928e-01\n",
      "  -2.60097441e-03  8.58243853e-03 -1.31679367e-01  3.99083609e-02\n",
      "  -1.67865327e-02 -1.42714449e-01 -1.58417966e-01  5.45107958e-02\n",
      "   2.45142562e-01 -9.96166312e-02  1.39766388e-01 -1.22847736e-01\n",
      "  -4.91301031e-02  8.67771009e-02 -6.41526126e-02  9.54886043e-02\n",
      "  -1.33140940e-01  1.35174949e-02  7.83655550e-02  9.41324926e-02\n",
      "  -6.94276975e-02 -4.56466910e-02  7.36591980e-02  1.37840028e-01\n",
      "   6.87466334e-03  2.47759105e-03 -1.54867354e-02 -3.81372083e-02\n",
      "  -1.80259458e-01 -1.15283942e-01 -1.16392880e-01 -2.01503758e-01\n",
      "  -3.27174955e-02  1.05748981e-01 -8.93831111e-02  2.62619264e-03\n",
      "  -1.05408531e-01  2.63470774e-01 -9.23459170e-02 -1.22604695e-01\n",
      "   1.34959410e-01 -2.94038561e-02 -1.95045194e-02  1.74458937e-01\n",
      "  -2.28002029e-02 -1.62906182e-01 -7.96772758e-02  7.78405903e-02\n",
      "  -7.79844137e-02  1.28713224e-01  6.97351775e-02 -1.81729118e-01\n",
      "   1.21696914e-01  1.55522619e-02  2.78162326e-02 -6.12005629e-02\n",
      "   1.35255656e-01 -1.92258222e-02 -5.93041788e-02 -9.32220816e-03\n",
      "   5.94802044e-02 -1.67775688e-01 -1.47628992e-02 -1.13424730e-01\n",
      "  -1.00935257e-01  4.89946068e-02  2.45964435e-03 -7.95414654e-02\n",
      "   1.85844416e-02  1.23992257e-01  6.38824733e-02 -9.74342621e-02\n",
      "  -5.45803333e-02 -6.83499702e-02  5.23225918e-02  2.39165600e-01\n",
      "  -6.32738463e-02 -4.44982907e-02  3.02166189e-01  1.70791716e-01\n",
      "   6.27087253e-02 -1.57836273e-01  3.49036656e-02  7.06171297e-02\n",
      "   1.39750361e-01  1.56391219e-01  2.28720188e-01  8.16895792e-02\n",
      "  -1.31015225e-02 -5.72028313e-03  3.97320259e-02  1.59207205e-01\n",
      "  -1.26474053e-01 -1.88012480e-01 -9.83968075e-02  1.81991705e-02\n",
      "   1.20640506e-01 -4.08986117e-04  9.30525846e-02  3.65145010e-02\n",
      "   4.10750197e-02  2.48054409e-02  1.21186535e-01 -9.26632897e-02\n",
      "  -9.70817748e-03 -3.61145354e-02 -1.13061473e-01 -1.24347524e-02\n",
      "   1.57015708e-01  1.86242920e-01  2.12386525e-01 -2.23407750e-01\n",
      "  -7.39780482e-02 -9.25972602e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Viewing the coefficents learned by the model\n",
    "coefs = lr_baseline.coef_\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358\n"
     ]
    }
   ],
   "source": [
    "print(len(coefs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4296, 358)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the training data into train and test to get an idea of the variance\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an random forest model with untuned hyperparameters\n",
    "\n",
    "# Importing the random forest model from scikit learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creating the random forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200,\n",
    "                                       oob_score=True,\n",
    "                                       class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=True, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the random forest model\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9762773250549734\n",
      "The recall is 0.920997920997921\n",
      "The precision is 0.3350983358547655\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, precision, and recall for the training set\n",
    "y_pred = rf_classifier.predict(X_train)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_train, y_pred))\n",
    "print(\"The recall is\", recall_score(y_train, y_pred))\n",
    "print(\"The precision is\", precision_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9652567585047213\n"
     ]
    }
   ],
   "source": [
    "# Getting the out of bag score\n",
    "print(rf_classifier.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9671787709497207\n",
      "The recall is 0.058823529411764705\n",
      "The precision is 0.03125\n"
     ]
    }
   ],
   "source": [
    "# Calculating the evaluation metrics for the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_test, y_pred))\n",
    "print(\"The recall is\", recall_score(y_test, y_pred))\n",
    "print(\"The precision is\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[train_data[\"RESPONSE\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42419"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[train_data[\"RESPONSE\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.73496240601504"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "42419 / 532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an gradient boosting model with untuned hyperparameters\n",
    "\n",
    "# Importing the random forest model from scikit learn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Creating the random forest model\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the gradient boosting model\n",
    "gb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9885913853317811\n",
      "The recall is 0.08316008316008316\n",
      "The precision is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, precision, and recall for the training set\n",
    "y_pred = gb_classifier.predict(X_train)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_train, y_pred))\n",
    "print(\"The recall is\", recall_score(y_train, y_pred))\n",
    "print(\"The precision is\", precision_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9871973929236499\n",
      "The recall is 0.0\n",
      "The precision is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, precision, and recall for the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_test, y_pred))\n",
    "print(\"The recall is\", recall_score(y_test, y_pred))\n",
    "print(\"The precision is\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the SMOTE class in order to oversample the positive class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Creating the SMOTE model\n",
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining X_train and y_train to include all the training data that will be oversampled \n",
    "X_train = train_data.loc[:, train_data.columns != 'RESPONSE']\n",
    "y_train = train_data['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42951, 358)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the SMOTE model to the training data and resampling the training data\n",
    "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1271c2898>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the new distribution of the RESPONSE column\n",
    "y_train_over.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8484, 358)\n"
     ]
    }
   ],
   "source": [
    "# Re-training the random forest model to see if there is any change in the recall\n",
    "\n",
    "# Creating a small test from the training data to get an idea of what the variance is\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_over, y_train_over, test_size=0.1)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Importing the random forest model from scikit learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creating the random forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200,\n",
    "                                       oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, oob_score=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the random forest model\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.948568509835765\n",
      "The recall is 0.9199202350965575\n",
      "The precision is 0.9756504800333936\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, precision, and recall for the training set\n",
    "y_pred = rf_classifier.predict(X_train)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_train, y_pred))\n",
    "print(\"The recall is\", recall_score(y_train, y_pred))\n",
    "print(\"The precision is\", precision_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9414191419141914\n",
      "The recall is 0.9071279312746692\n",
      "The precision is 0.9757742257742258\n"
     ]
    }
   ],
   "source": [
    "# Calculating the evaluation metrics for the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_test, y_pred))\n",
    "print(\"The recall is\", recall_score(y_test, y_pred))\n",
    "print(\"The precision is\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 0.9431463970453414\n",
      "The recall is 0.9090575146935348\n",
      "The precision is 0.975366684496495\n",
      "The accuracy is 0.9411834040546911\n",
      "The recall is 0.9071279312746692\n",
      "The precision is 0.9752870693959061\n"
     ]
    }
   ],
   "source": [
    "# Repeating the process for the gbm and xgb models\n",
    "# Creating an gradient boosting model with untuned hyperparameters\n",
    "\n",
    "# Importing the random forest model from scikit learn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Creating the random forest model\n",
    "gb_classifier = GradientBoostingClassifier(n_estimators=200)\n",
    "\n",
    "# Training the gradient boosting model\n",
    "gb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Calculating the accuracy, precision, and recall for the training set\n",
    "y_pred = gb_classifier.predict(X_train)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_train, y_pred))\n",
    "print(\"The recall is\", recall_score(y_train, y_pred))\n",
    "print(\"The precision is\", precision_score(y_train, y_pred))\n",
    "\n",
    "# Calculating the accuracy, precision, and recall for the test set\n",
    "y_pred = gb_classifier.predict(X_test)\n",
    "\n",
    "print(\"The accuracy is\", accuracy_score(y_test, y_pred))\n",
    "print(\"The recall is\", recall_score(y_test, y_pred))\n",
    "print(\"The precision is\", precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
